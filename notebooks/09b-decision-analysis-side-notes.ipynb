{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec275fc-695c-4c16-ae54-e45420382acb",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wikipedia says:\n",
    "In a quantitative decision-analysis model:\n",
    "* uncertainties are represented through probabilities -- specifically, subjective probabilities.\n",
    "* The decision maker's attitude to risk is represented by utility functions, and\n",
    "* the attitude to trade-offs between conflicting objectives can be expressed using multi-attribute value functions or multi-attribute utility functions (if there is risk involved). (In some cases, utility functions can be replaced by the probability of achieving an uncertain aspiration level or \"target\".)\n",
    "\n",
    "Based on the axioms of decision analysis, the best decision to choose is the one whose consequences have the maximum expected utility (or that maximizes the probability of achieving the uncertain aspiration level)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426346e-d6ff-429b-9321-3fa5554ca037",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TL;DR\n",
    "How you shift your guesses to maximise your chances of winning, at the expense of reducing your risk, and your expected gains based on:\n",
    "* The historical showcase prices\n",
    "* Your guess for the current showcase\n",
    "* Your ability to guess right\n",
    "* How well your opponent performed in the past.\n",
    "* How close you get to the showcase price\n",
    "\n",
    "We will call this shift the Bayes strategy throughout the notebook.\n",
    "\n",
    "# Procedure:\n",
    "Let $\\boldsymbol{X}$ be a random variable that represents the value of the current showcase price. We can estimate $\\boldsymbol{X}$ by:\n",
    "\n",
    "$$\\boldsymbol{X}\\sim \\text{argmax}_a\\text{ }L(a)$$\n",
    "\n",
    "which means that we are seeking the price $a$ that maximizes the objective function $L$, that is defined as follows:\n",
    "\n",
    "$$L = \\sum_{j=1}\\mathbf{b}\\cdot\\mathbf{C}$$\n",
    "\n",
    "Which is the sum over rows of the dot product between the probability of the current showcase and the matrix of all possible outcomes, more specifically:\n",
    "* $\\mathbf{b} = P(h|e)$, a bayesian estimation of the current price $a$ based on the ground truth of historical prices $h$ given our guess for the current showcase and our ability to guess right $e$\n",
    "* $\\mathbf{C}$, represents our chances of winning depending how off we fall from the price and how well we perform with respect to our opponent for each possible price in the $a$ range of prices\n",
    "\n",
    "Let's start first with the frog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654e325-2b10-41e9-b578-000a6ce504e3",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Chances matrix\n",
    "$\\mathbf{C}$ is the heart of decision theory that states that for any decision problem you have there are:\n",
    "* a set of states that do not depend on you, and\n",
    "* a set of actions that you can perform\n",
    "\n",
    "Then, for every pair state-action you assign a value. The moment you do this you have a decision preference that follows the [von Neumann-Morgenstern](https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem) rules\n",
    "\n",
    "In this case the states are the possible prices of the showcase and the actions are the bids. The value is generated as follows:\n",
    "\n",
    "$$\n",
    "f(P_i, P_j) =\n",
    "  \\begin{cases}\n",
    "    0          & \\quad \\text{if } P_i - P_j > 0 \\text{ (you overbid)}\\\\\n",
    "    p_b + p_o  & \\quad \\text{otherwise }\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$p_b$ is the probability of your opponent underbidding by more than you.\n",
    "$p_o$ is the probability of your opponent overbidding.\n",
    "We calculate these based on previous results.\n",
    "This is a small sample of what the matrix could look like:\n",
    "```\n",
    "p = {1, 2, 3}  # The range of possible prices\n",
    "\n",
    "      pi - pj      f(pi, pj)\n",
    "    1   2   3\n",
    "1   0   1   2     .5   0   0\n",
    "2  -1   0   1  => .2  .5   0\n",
    "3  -2  -1   0     .1  .2  .2\n",
    "```\n",
    "Where the rows represent the possible prices (states) and the columns represent possible bids (actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c58362-01e9-42ce-934e-6f46a53d470a",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bayes estimator\n",
    "Of course not all the prices have the same probability to appear, so we need to come up with an estimate of this probability. To do so we start off some ground truth that are previous prices:\n",
    "$h = \\text{kde(historical\\_prices)}$\n",
    "\n",
    "Then, we have the likelihood that represents our ability of guessing right defined as:\n",
    "$e = \\mathcal{N}(\\mu=g, \\sigma=std(error))$\n",
    "\n",
    "Where $g$ is our current guess and $std(error)$ is the standard deviation of our previous guesses. This assumes that over the long haul we always guess right, that is, if some price is 20k and we guess 22k, then there will be some other time when the price being again 20k (for simplicity) we guess 18k.\n",
    "\n",
    "## Sum over rows\n",
    "So we have a matrix with chances of winning depending the showcase price, the amount we bid and a vector that tells us the probability of some price to appear. Thus, we can multiply each price by its probability to appear and then sum over rows to get the chances for each bid (remember that columns represent bids).\n",
    "\n",
    "With this we are left with a probability distribution for each bid from where we are looking for the $\\mathrm{argmax}$, that is, the bid that maximises our options of winning.\n",
    "\n",
    "## Maximizing the expected gains\n",
    "Above approach is conservative meaning that the objective function will reduce our optimal bid to avoid overbidding, but we can increase a bit the expected gains at the expense of being riskier because if we underbid within \\$250, we will win both showcases. So in the chances of winning we can do the following:\n",
    "\n",
    "$$\n",
    "f(P_i, P_j) =\n",
    "  \\begin{cases}\n",
    "    0          & \\quad \\text{if } P_i - P_j > 0 \\text{ (you overbid)}\\\\\n",
    "    k\\cdot(p_b + p_o)  & \\quad \\text{if }250 < P_i - P_j < 0 \\text{ (winning both)}\\\\\n",
    "    p_b + p_o  & \\quad \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "Where $k$ is a risk factor that we can adjust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c22429-f8de-4498-9eff-8fb220db9e9b",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Crunching the numbers\n",
    "Let's translate all above to the algorithm. To start with, we import the data.\n",
    "\n",
    "## Import historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ceeaf-704f-41fc-b9b7-f1b4720b487a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     showcase_1  showcase_2    bid_1    bid_2  diff_1  diff_2\n127     26732.0     28480.0  18000.0  21000.0 -8732.0 -7480.0\n171     25366.0     26525.0  21000.0  24050.0 -4366.0 -2475.0\n181     27690.0     41765.0  23000.0  36000.0 -4690.0 -5765.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>showcase_1</th>\n      <th>showcase_2</th>\n      <th>bid_1</th>\n      <th>bid_2</th>\n      <th>diff_1</th>\n      <th>diff_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>127</th>\n      <td>26732.0</td>\n      <td>28480.0</td>\n      <td>18000.0</td>\n      <td>21000.0</td>\n      <td>-8732.0</td>\n      <td>-7480.0</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>25366.0</td>\n      <td>26525.0</td>\n      <td>21000.0</td>\n      <td>24050.0</td>\n      <td>-4366.0</td>\n      <td>-2475.0</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>27690.0</td>\n      <td>41765.0</td>\n      <td>23000.0</td>\n      <td>36000.0</td>\n      <td>-4690.0</td>\n      <td>-5765.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the data\n",
    "def read_data(filename):\n",
    "    \"\"\"Read the showcase price data.\"\"\"\n",
    "    df = pd.read_csv(filename, index_col=0, skiprows=[1])\n",
    "    df = df.dropna().transpose()\n",
    "    df = df.rename(columns={\n",
    "        'Showcase 1': 'showcase_1',\n",
    "        'Showcase 2': 'showcase_2',\n",
    "        'Bid 1': 'bid_1',\n",
    "        'Bid 2': 'bid_2',\n",
    "        'Difference 1': 'diff_1',\n",
    "        'Difference 2': 'diff_2',\n",
    "    })\n",
    "    # it turns out that diffs are swapped\n",
    "    df.loc[:, 'diff_1'] = -df.diff_1\n",
    "    df.loc[:, 'diff_2'] = -df.diff_2\n",
    "    return df\n",
    "\n",
    "df2011 = read_data('data/showcases.2011.csv')\n",
    "df2012 = read_data('data/showcases.2012.csv')\n",
    "df = pd.concat([df2011, df2012], ignore_index=True)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508ee1e-7284-4a5a-85a8-1f0f86cb7ccc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create the bayesian estimator\n",
    "**Exercise:**\n",
    "You might want to reproduce the bayes table of the estimations\n",
    "* build a bayes table with the priors\n",
    "* calculate likes for 23k and 38k\n",
    "* calculate posteriors\n",
    "* plot the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f4200c-8a28-4996-99c1-d8c2cd331733",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# buid a bayes table with all the data\n",
    "# min showcase ever 18.3k, max 71.6k\n",
    "# let's give some decent resolution to compute the maximization of the gains\n",
    "price_range = np.linspace(10_000, 80_000, 1401)\n",
    "bt = pd.DataFrame({\n",
    "    \"prior1\": gaussian_kde(df.showcase_1).pdf(price_range),\n",
    "    \"prior2\": gaussian_kde(df.showcase_2).pdf(price_range),\n",
    "}, index=price_range)\n",
    "\n",
    "# Calculate likes, this measures how wrong we were in the past.\n",
    "bt[\"like1\"] = norm(23_000, df.diff_1.std()).pdf(price_range)\n",
    "bt[\"like2\"] = norm(38_000, df.diff_2.std()).pdf(price_range)\n",
    "\n",
    "bt[\"post1\"] = bt.prior1 * bt.like1\n",
    "bt[\"post2\"] = bt.prior2 * bt.like2\n",
    "\n",
    "# Normalize data\n",
    "def normalize_column(df, col_name):\n",
    "    df[col_name] /= df[col_name].sum()\n",
    "\n",
    "[normalize_column(bt, col) for col in (\n",
    "    \"prior1\", \"prior2\", \"like1\", \"like2\", \"post1\", \"post2\")\n",
    "]\n",
    "\n",
    "# Plot distributions\n",
    "sns.lineplot(x=bt.index, y=bt.prior1, label=\"prior\")\n",
    "sns.lineplot(x=bt.index, y=bt.post1, label=\"posterior\")\n",
    "\n",
    "# Print some data\n",
    "prior_expected_price = np.sum(bt.prior1 * bt.index).round(0)\n",
    "posterior_expected_price = np.sum(bt.post1 * bt.index).round(0)\n",
    "print(f\"The expected value with historical data is {prior_expected_price}\")\n",
    "print(f\"The expected value after adding our observations is {posterior_expected_price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ab19b-70ea-4e80-baf5-ddbafec89737",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create the chances matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d303efb-42a1-4e9d-896d-a4500d2f9de9",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_chances_of_winning(off_range, diff_series, k=1):\n",
    "    \"\"\"\n",
    "    Compute the probability of winning depending on your opponent performance.\n",
    "\n",
    "    Args:\n",
    "        * off_range: how off you fall from the showcase price.\n",
    "        * diff_series: how well your opponent performs\n",
    "        * k: risk factor to maximise the gains\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: all this can be made without iterating over rows in the off_ranges. Figure out how\n",
    "    chances = off_range.copy()\n",
    "\n",
    "    # if you overbid, you loose\n",
    "    chances[off_range > 0] = 0\n",
    "\n",
    "    # if your opponent overbids you win\n",
    "    opponent_overbids = (diff_series > 0).mean()\n",
    "\n",
    "    # Alternatively if you underbid by less than your opponent you win\n",
    "    vx, vy = np.meshgrid(diff_series, off_range)\n",
    "    opponent_underbids_by_more = (vx < vy).mean(axis=1)\n",
    "\n",
    "    # Get the sum of above\n",
    "    chances_under_0 = opponent_underbids_by_more + opponent_overbids\n",
    "\n",
    "    # Increase close to 0 bids by risk factor\n",
    "    chances_under_0[(-250 <= off_range) & (off_range <= 0)] *= k\n",
    "\n",
    "    # Add to the chances that are not 0 (as they were assigned in the first step)\n",
    "    chances[off_range <= 0] = chances_under_0[off_range <= 0]\n",
    "\n",
    "    return chances\n",
    "\n",
    "# we need to create a off range centered at current price for each price in the\n",
    "# price range.\n",
    "_, vy = np.meshgrid(price_range, price_range)  # broadcast price range onto a new axis\n",
    "off_ranges = price_range - vy\n",
    "\n",
    "# slightly faster than the equivalent for loop but more clean. This roughly means: compute\n",
    "# the chances of winning over rows in the off_ranges array.\n",
    "chances_matrix_k1 = np.apply_along_axis(\n",
    "    get_chances_of_winning, 1, off_ranges, diff_series=df.diff_2\n",
    ")\n",
    "chances_matrix_k4 = np.apply_along_axis(\n",
    "    get_chances_of_winning, 1, off_ranges, diff_series=df.diff_2, k=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44261c29-783c-45a3-a6b8-50fc0748a66f",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(chances_matrix_k1) / chances_matrix_k1.max()\n",
    "df1.index = price_range\n",
    "df1 = df1.rename(columns={n: pr for n, pr in enumerate(price_range)})\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(df1, ax=ax);\n",
    "ax.set_title(\"Chances matrix.\")\n",
    "ax.set_xlabel(\"Your bid\"), ax.set_ylabel(\"showcase price\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "055886f7-9862-4c89-8701-2fa1ededccca",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sum over rows and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab0ed3-a0dc-4c99-9467-c9a9964935dc",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k1 = (chances_matrix_k1.T * bt.post1.values).T\n",
    "df1 = pd.DataFrame(k1) / k1.max()\n",
    "df1.index = price_range\n",
    "df1 = df1.rename(columns={n: pr for n, pr in enumerate(price_range)})\n",
    "_, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(df1, ax=ax);\n",
    "ax.set_title(\"Chances matrix under price estimator.\")\n",
    "ax.set_xlabel(\"Your bid\"), ax.set_ylabel(\"showcase price\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0c1cf-5c48-4a36-a91f-e82542a0e64a",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k1 = k1.sum(axis=0)\n",
    "k1 /= k1.sum()\n",
    "sns.lineplot(x=price_range, y=k1, label='without risk');\n",
    "\n",
    "k4 = (chances_matrix_k4.T * bt.post1.values).T.sum(axis=0)\n",
    "k4 /= k4.sum()\n",
    "sns.lineplot(x=price_range, y=k4, label='risk=4');\n",
    "opt1, opt4 = [pd.Series(array, index=price_range).idxmax() for array in (k1, k4)]\n",
    "print(f\"The optimal bid without risk is {opt1}\")\n",
    "print(f\"The optimal risk=4 is {opt4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe4cd7-2a11-4d32-aa0d-a9eaad1eeae5",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gaussian KDE playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10ecaa-af91-4316-bbed-45570dd4cbf5",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample = np.random.normal(size=500)\n",
    "x_range = np.linspace(-5, 5, 100)\n",
    "\n",
    "kde = gaussian_kde(sample)\n",
    "y = kde(x_range)\n",
    "\n",
    "n_dist = norm.pdf(x_range)\n",
    "\n",
    "sns.lineplot(x=x_range, y=y);\n",
    "sns.lineplot(x=x_range, y=n_dist);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe5703-4ae4-444c-a5ee-889cf2517f77",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Performance strategy\n",
    "By means of the `bayes_predictions.py` script we can compute what happens when both players play this same strategy for 4 historical games (initially we computed for 50, 100, 200 & 300 games but it wasn't very relevant)\n",
    "\n",
    "It could be interesting to know:\n",
    "* How better is the bayes strategy with respect to the non-bayes strategy?\n",
    "* If we have a guessing accuracy over the long run slightly higher than the real price, does the bayes strategy help us?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbf189-e2d6-4f76-a8bd-0c20d021ea03",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Original guesses vs bayesian guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562d1ba-a63f-498d-9c54-1d9766925a09",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k4 = pd.read_csv(\"09-outcomes/showcases-4.csv\", index_col=0)\n",
    "\n",
    "# Visualize how different are the original guesses with respect to the bayes approach\n",
    "p1_diffs = k4[[\"diff_1\", \"estimated_diff1\"]]\n",
    "diff_range = np.linspace(p1_diffs.min().min(), p1_diffs.max().max(), 200)\n",
    "kde0, kde1 = [gaussian_kde(d)(diff_range) for d in (k4.diff_1, k4.estimated_diff1)]\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.lineplot(x=diff_range, y=kde0, label=\"original\")\n",
    "sns.lineplot(x=diff_range, y=kde1, label=\"bayesian\")\n",
    "sns.despine()\n",
    "ax.set_xlabel(\"Bid offset\"), ax.set_ylabel(\"Probability\")\n",
    "ax.set_title(\"Original vs Bayesian bid\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0cb1c-e73e-4dfd-900d-2c6efde3bc59",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, Span, Label\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debda2d-54cb-49d0-9cb6-8332582aad66",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Original performance vs bayesian performance\n",
    "\n",
    "### History 4 analysis\n",
    "* With the original approaches p1 performs slightly better 51.2%. But when both play bayes p2 manages to outperform (by very few) 50.2%. This could be an statistical fact meaning that since both are playing the same strategy they are approaching a nash equilibrium that eventually\n",
    "* We reach the minimun no winner when both play the bayes strategy.\n",
    "* p1 performs slightly better when he plays bayes and p2 follows the original strategy. Mostly at the expense of reducing the no winner (.07 -> .019) but also a bit at the expense of reducing the chances of p2 (.45->.44)\n",
    "* p2 does not increase its performance as much as p1 when he plays the bayes strategy mainly because it's not able to reduce the no_winner (.07->.031) as the amount it takes from p1 is the same amount p1 takes from p1 in the reverse situation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181db7ca-3411-42de-aa2a-c2d85d4e867c",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"09-outcomes/showcases-4.csv\", index_col=0)\n",
    "\n",
    "def determine_winner(diff1, diff2):\n",
    "    \"\"\"Determine the winner for two given diffs from the original price.\"\"\"\n",
    "    winner_array = np.zeros(diff1.shape)  # Where zero means no winner\n",
    "    p1_overbids = diff1 > 0\n",
    "    p2_overbids = diff2 > 0\n",
    "    p1_gt_p2 = diff1 > diff2\n",
    "    p1_wins = ((p1_gt_p2 | p2_overbids) & ~p1_overbids)\n",
    "    p2_wins = ((~p1_gt_p2 | p1_overbids) & ~p2_overbids)\n",
    "    winner_array[p1_wins] = 1\n",
    "    winner_array[p2_wins] = 2\n",
    "    return winner_array.astype(int).astype(str)\n",
    "\n",
    "def add_strategies_to_df(df):\n",
    "    df['original'] = determine_winner(df.diff_1, df.diff_2)\n",
    "    df['p1_bayes'] = determine_winner(df.estimated_diff1, df.diff_2)\n",
    "    df['p2_bayes'] = determine_winner(df.diff_1, df.estimated_diff2)\n",
    "    df['both_bayes'] = determine_winner(df.estimated_diff1, df.estimated_diff2)\n",
    "    return df\n",
    "\n",
    "def get_improvement(df):\n",
    "    df = add_strategies_to_df(df)\n",
    "    cols = (\"original\", \"p1_bayes\", \"p2_bayes\", \"both_bayes\")\n",
    "    data = {col: df.groupby(col).bid_1.count().values / df.shape[0] for col in cols}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "get_improvement(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4b163-c78a-4125-a8af-5fb57bb990d1",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_it(title, x, y, category, df):\n",
    "    s0 = ColumnDataSource(df)\n",
    "    tooltips = [\n",
    "        (\"p1 diff\", \"$x\"),\n",
    "        (\"p2 diff\", \"$y\"),\n",
    "        (\"index\", \"$index\"),\n",
    "    ]\n",
    "    p = figure(title=title, height=400, width=400, tooltips=tooltips)\n",
    "    c_map = factor_cmap(category, palette=Spectral6[:3], factors=df[category].unique())\n",
    "    p.scatter(x=x, y=y, source=s0, color=c_map, legend_field=category)\n",
    "\n",
    "    for dim in ('height', 'width'):\n",
    "        span = Span(location=0, dimension=dim)\n",
    "        p.add_layout(span)\n",
    "\n",
    "\n",
    "    p.xaxis.axis_label = 'p1 diff from real price'\n",
    "    p.yaxis.axis_label = 'p2 diff from real price'\n",
    "    p.legend.location = 'bottom_left'\n",
    "    return p\n",
    "\n",
    "def plot_layout(df):\n",
    "    layout = gridplot([\n",
    "        [\n",
    "            plot_it(\n",
    "                title=\"Both original strategies\", x='diff_1', y='diff_2',\n",
    "                category='original', df=df\n",
    "            ),\n",
    "            plot_it(\n",
    "                title=\"Both bayes strategies\", x='estimated_diff1', y='estimated_diff2',\n",
    "                category='both_bayes', df=df\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            plot_it(\n",
    "                title=\"P1 bayes\", x='estimated_diff1', y='diff_2',\n",
    "                category='p1_bayes', df=df\n",
    "            ),\n",
    "            plot_it(\n",
    "                title=\"P2 bayes\", x='diff_1', y='estimated_diff2', category='p2_bayes',\n",
    "                df=df\n",
    "            ),\n",
    "        ]\n",
    "    ])\n",
    "\n",
    "    show(layout)\n",
    "plot_layout(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c9bfc-6f18-4216-9e83-d3ab4f333747",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### p1 playing worse improvement\n",
    "In this section we are going to analyze what happens if p1 is overall a bad guesser but however uses the bayes approach.\n",
    "\n",
    "#### Overall worse feel\n",
    "Let's take a look at several worsen factors. First there's a table that shows how the factor affects the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8e7ed-abf5-4183-8332-10b2e5203f46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df2011 = read_data('data/showcases.2011.csv')\n",
    "df2012 = read_data('data/showcases.2012.csv')\n",
    "\n",
    "worsen_factor = [1.05, 1.1, 1.2, 1.3]\n",
    "outcomes = dict()\n",
    "for wf in worsen_factor:\n",
    "    df = pd.concat([df2011, df2012], ignore_index=True)\n",
    "    df.loc[:, 'bid_1'] = np.random.normal(df.showcase_1 * wf, df.diff_1.std())\n",
    "    df.loc[:, 'diff_1'] = df.bid_1 - df.showcase_1\n",
    "    df['original'] = determine_winner(df.diff_1, df.diff_2)\n",
    "    outcomes[wf] = (df.groupby('original').count() / df.shape[0]).bid_1.values\n",
    "print(\"Outcomes as a function of worsen factor\")\n",
    "pd.DataFrame(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e2c06-b002-46e7-bf94-ef6930fd7912",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Worse factor 1.05 analysis\n",
    "* P1 wins 33% of the times with it's original strategy (that tends to overshoot by 1.05 on the real price)\n",
    "* It maximizes its wins if it plays bayes while the opponent doesn't. And also this strategy reduces p2 winns to 42%\n",
    "* If p2 plays Bayes while p1 doesn't, p2 maximises its winns to a 63%\n",
    "* As before, both playing bayes strategy minimises the house wins and makes p1 outperform p2 even by more than the original approach. This could be because of the fact that as p1 is overshooting and the bayes strategy shifts back its bids that makes it underbid by less than p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367366e-da5b-4926-a358-c755441473d2",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"09-outcomes/showcases-4-1_05-worse.csv\", index_col=0)\n",
    "get_improvement(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2f369-9862-4721-82d0-ce93a5aab0f5",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_layout(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96892b-4109-4beb-800a-5ad542d81b59",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Worse factor 1.3\n",
    "With worse factor 1.3 p1 is too off to outperform p2 but still both playing bayes minimises the wins of the house. Also, since p1 is really bad, bayes strategy makes p2 reach a 86% of wins as it's reducing its risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1a349-34d3-4815-be6b-bdd0d338c6e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"09-outcomes/showcases-4-1_3-worse.csv\", index_col=0)\n",
    "get_improvement(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e6d66-bc32-4ed9-b057-8325382a1555",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_layout(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d6a10-f53d-427b-972e-d41ad2362d3d",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiment: try to get rid of the for loop\n",
    "It could be great to avoid the for loop when comparing off_ranges. However it's not possible as one hits the `MemoryError` when trying to broadcast to the multiple lines in the `off_ranges` array\n",
    "```\n",
    "Unable to allocate 1.57 TiB for an array with shape (1962801, 438513) and data type int16\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb4983-1913-405e-a928-5d892853fb9b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a much simpler version of what we try to achieve.\n",
    "a = np.array([\n",
    "    [0., 1, 2],\n",
    "    [-1, 0, 1],\n",
    "    [-2, -1, 0],\n",
    "])\n",
    "b = np.array([-1, -3])\n",
    "\n",
    "cmk = a.copy()\n",
    "\n",
    "# if you overbid, you loose\n",
    "cmk[a > 0] = 0\n",
    "\n",
    "# if your opponent overbids you win\n",
    "opponent_overbids = (b > 0).mean()\n",
    "\n",
    "# Alternatively if you underbid by less than your opponent you win\n",
    "vx, _ = np.meshgrid(b, a[0])  # get a broadcast version of 'b' with the shape of one of the rows in 'a'\n",
    "vx, vy = np.meshgrid(vx, a)  # get broadcast versions of both vx and 'a' such that we can compare elementwise\n",
    "c = (vx < vy).mean(axis=1)\n",
    "\n",
    "cu0 = opponent_overbids + c\n",
    "\n",
    "cmk[a <= 0] = cu0[a.ravel() <= 0]\n",
    "(cmk == np.apply_along_axis(get_chances_of_winning, 1, a, diff_series=b)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96852fb8-f02a-4050-9438-adb3415e1ff5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Even if you downgrade the size of the elements you still hit the error\n",
    "ori = off_ranges.astype(np.int16)\n",
    "diff = df.diff_2.values.astype(np.int16)\n",
    "cmk1 = ori.copy()\n",
    "\n",
    "# if you overbid, you loose\n",
    "cmk1[ori > 0] = 0\n",
    "\n",
    "# if your opponent overbids you win\n",
    "opponent_overbids = (diff > 0).mean()\n",
    "\n",
    "# Alternativelly if you underbid by less than your opponent you win\n",
    "vx, _ = np.meshgrid(diff, ori[0])\n",
    "# vx, vy = np.meshgrid(vx, ori)  # this hits MemoryError\n",
    "# opponent_underbids_by_more = (vx < vy).mean(axis=1)\n",
    "\n",
    "# Sum both probabilities\n",
    "# cu0 = opponent_underbids_by_more + opponent_overbids\n",
    "\n",
    "# broadcast the array to compare against off_ranges\n",
    "# chances_under_0, _ = np.meshgrid(cu0, cu0)\n",
    "# cmk1[ori <= 0] = chances_under_0[ori <= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d9633-acc5-4cc5-b494-880cba7d1839",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Redline Problem\n",
    "## Goal\n",
    "Estimate the waiting time as a function $f$ of the people ($\\text{pax}$) we see in the station when we arrive.\n",
    "\n",
    "Especifically: $f(\\text{pax}) = \\mathbf{E}[z - x(\\text{pax})]$\n",
    "\n",
    "We want the expected value $\\mathbf{E}$ of the difference between the gap time $z$ and the elapsed time as a function of the number of people $x(\\text{pax})$ we see in the station when we arrive. Because:\n",
    "\n",
    "$\\text{gap time} = \\text{elapsed time} + \\text{waiting time}$\n",
    "\n",
    "And therefore:\n",
    "\n",
    "$\\text{waiting time} = \\text{gap time} - \\text{elapsed time}$\n",
    "\n",
    "## Estimate gap time $z$\n",
    "The gap time is the posterior probability of the `observed_gap_times` given that I'm more likely to land in a longer gap than into a shorter one.\n",
    "\n",
    "We call this `posterior_z` in the code\n",
    "\n",
    "**Include outliers**\n",
    "We know that sometimes there are long delays so we might want to include them in our estimations. To do so we will sample 261 values out of this posterior distribution which, recall, is our perception of the train gaps, and then add three delays of 30, 40 & 50 minutes.\n",
    "\n",
    "We will call this `augmented_posterior_z` in the code\n",
    "\n",
    "## Estimate elapsed time as a function of the pax $x(\\text{pax})$\n",
    "In short, we will estimate the elapsed time as the posterior probability of weighted general elapsed times given that we find $\\text{pax}$ people in the station assuming that people arrive at a constant rate of 2pax/m (which we can challenge)\n",
    "\n",
    "**Weighted general elapsed times**\n",
    "A simple example, if trains' gap is:\n",
    "* 1' you have 100% chances to catch the train in the minute you arrive\n",
    "* 5' you have 20% chanches to catch the train in the minute you arrive, 20% chances of catching it after 2', 20% chances after 3' and so on.\n",
    "* 10' you have 10% chances to catch the train in the minute you arrive, 10% after 2' and so on.\n",
    "\n",
    "This way we have 43% chances of catching the train in the first minute, 10% in the 2-5 interval and 33% in the 6-10 interval\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "one, five, ten = [1, ], [1/5, ] * 5, [1/10, ] * 10\n",
    "data = pd.DataFrame([one, five, ten])\n",
    "# normalize values to avoid 130% on the first minute\n",
    "data.sum() / data.sum().sum()\n",
    "```\n",
    "\n",
    "However, not all the gaps are equally likely, so we can weight them by our perception of time gaps (as I'm more likely to land in a longer gap than in a shorter one).\n",
    "\n",
    "This is called in the code `prior_x`\n",
    "\n",
    "**Likelihood function**\n",
    "We can think of the pax arrival as a poisson process with rate of 2pax/min. With this in mind, we can compute the likelihood of finding $\\text{pax}$ for each minute in the train gap. This will tell us that finding, for instance, 10 people is the most likely ($0.12$) when 5 minutes have elapsed since last train whereas finding those 10pax is quite unlikely ($1.6\\cdot10^{-10}$) when last train just left.\n",
    "\n",
    "$l\\sim\\mathrm{Poisson}(\\lambda=2)$\n",
    "\n",
    "## Get the waiting time $y$\n",
    "To get the waiting time we need all possible differences between all the gap times and all the moments I could arrive and then weight them by the joint probability of both events happening (the gap and my arrival) and then sum the probabilities for equal diffs. For instance, I can wait 5' by arriving in the:\n",
    "* 5th minute in a 10' gap, or\n",
    "* 7th minute in a 12' gap, or\n",
    "* 10th minute in a 15' gap\n",
    "\n",
    "And so on. As those events have different probabilities and are mutually exclusive (`or`), we can sum them.\n",
    "\n",
    "This difference yields negative values meaning that when the train has gone. Put it another way, if the last train's gap was 5' and I arrived in the 7' I'm not going to catch it never. Therefore we should get rid of those weird values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c0a03",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Code\n",
    "### Initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aefc81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import poisson\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Initial data\n",
    "observed_gap_times = [\n",
    "    428.0, 705.0, 407.0, 465.0, 433.0, 425.0, 204.0, 506.0, 143.0, 351.0,\n",
    "    450.0, 598.0, 464.0, 749.0, 341.0, 586.0, 754.0, 256.0, 378.0, 435.0,\n",
    "    176.0, 405.0, 360.0, 519.0, 648.0, 374.0, 483.0, 537.0, 578.0, 534.0,\n",
    "    577.0, 619.0, 538.0, 331.0, 186.0, 629.0, 193.0, 360.0, 660.0, 484.0,\n",
    "    512.0, 315.0, 457.0, 404.0, 740.0, 388.0, 357.0, 485.0, 567.0, 160.0,\n",
    "    428.0, 387.0, 901.0, 187.0, 622.0, 616.0, 585.0, 474.0, 442.0, 499.0,\n",
    "    437.0, 620.0, 351.0, 286.0, 373.0, 232.0, 393.0, 745.0, 636.0, 758.0,\n",
    "]\n",
    "observed_gap_times = np.array(observed_gap_times) / 60  # as above times are in seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4933aa1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Estimate z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f81913",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time_range = np.linspace(0, 20, 81)\n",
    "prior_z = gaussian_kde(observed_gap_times).pdf(time_range)\n",
    "\n",
    "# the likelihood of landing in a certain gap is proportional to the length of the gap.\n",
    "likes_z = time_range.copy()\n",
    "\n",
    "# Compute posterior\n",
    "posterior_z = prior_z * likes_z\n",
    "posterior_z /= posterior_z.sum()  # Normalize\n",
    "\n",
    "# Sample 261 values from above posterior\n",
    "np.random.seed(10)\n",
    "time_series = pd.Series(time_range)\n",
    "samples = time_series.sample(261, weights=posterior_z, replace=True)\n",
    "samples = np.append(samples, [30, 40, 50])\n",
    "extended_time_range = np.linspace(0, 60, 121)\n",
    "augmented_posterior_z = gaussian_kde(samples).pdf(extended_time_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad221e62",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce6f1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prior_x = pd.DataFrame([\n",
    "    n * [1/n] for n, _ in enumerate(extended_time_range, start=1)\n",
    "]).fillna(0)\n",
    "\n",
    "# Weight the elapsed times as not all the gaps are equally likely.\n",
    "prior_x = (prior_x.T * augmented_posterior_z).sum(axis=1)\n",
    "lambdas = 2 * extended_time_range\n",
    "\n",
    "def get_posterior_x(pax):\n",
    "    \"\"\"Get the posterior probability for the elapsed time.\"\"\"\n",
    "    likes_x = poisson(lambdas).pmf(pax)\n",
    "    posterior_x = prior_x * likes_x\n",
    "    posterior_x /= posterior_x.sum()\n",
    "    return posterior_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded5bfd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Estimate y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aece3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def waiting_time(pax):\n",
    "    \"\"\"Calculate the mean waiting time as a function of the pax in the platform.\"\"\"\n",
    "    posterior_x = get_posterior_x(pax)\n",
    "\n",
    "    # Compute waiting times\n",
    "    vx, vy = np.meshgrid(extended_time_range, extended_time_range)\n",
    "    waiting_time = vx - vy\n",
    "\n",
    "    vx, vy = np.meshgrid(augmented_posterior_z, posterior_x)\n",
    "    joint_p = vx * vy\n",
    "\n",
    "    posterior_y = pd.DataFrame({\n",
    "        \"waiting_time\": waiting_time.ravel(),\n",
    "        \"joint_p\": joint_p.ravel()\n",
    "    }).groupby(\"waiting_time\").joint_p.sum()\n",
    "\n",
    "    # Only take into account positive values as negative ones mean that we lost\n",
    "    # the train\n",
    "    posterior_y = posterior_y[posterior_y.index >= 0]\n",
    "\n",
    "    posterior_y /= posterior_y.sum()  # Normalize\n",
    "    return np.sum(posterior_y.index.values * posterior_y.values)\n",
    "\n",
    "waiting_time_series = pd.Series(\n",
    "    [waiting_time(pax) for pax in range(38)]\n",
    ")\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.set_title(\"Waiting time as a function of the people in the station\")\n",
    "ax.set_xlabel(\"Pax\")\n",
    "ax.set_ylabel(\"Waiting time in minutes\")\n",
    "waiting_time_series.plot()\n",
    "waiting_time_series.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f8adf2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}