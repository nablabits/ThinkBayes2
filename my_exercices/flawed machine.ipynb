{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea5d22a-88d9-4582-9344-71206341910b",
   "metadata": {},
   "source": [
    "#### Hypothesis space\n",
    "The hypothesis space represents all possible fairnesses of the coin where 0 means 100% tail biased and 1 100% head-biased.\n",
    "\n",
    "#### Calculating likelihoods\n",
    "**Non flawed machine:**\n",
    "For a non-flawed machine we can trust the outcome of what it sees, so the likelihoods are as follows:\n",
    "* $H_l: hs$; fliping heads agrees with the hypothesis space\n",
    "* $T_l: 1-hs$; flipping tails is against the hypothesis space\n",
    "\n",
    "**Full flawed machine**\n",
    "For a full flawed machine is the other way round. This means that when the machine sees a head, it's indeed a tail:\n",
    "* $H_l: 1-hs$; fliping heads is against the hypothesis space (as we actually flipped a tail, not a head)\n",
    "* $T_l: hs$; flipping tails agrees with the hypothesis space\n",
    "\n",
    "**Half-flawed machine**\n",
    "For a half-flawed machine no matter the outcome of the flip, half of the hypothesis space aggrees with the result and the other half disagrees:\n",
    "* $H_l: .5\\cdot hs + .5\\cdot(1-hs)$\n",
    "* $T_l: .5\\cdot hs + .5\\cdot(1-hs)$    \n",
    "\n",
    "This, effectively, bring us back to the starting point where every hypothesis is equally probable. We are substituting the randomness of a coin by the randomness of the machine.\n",
    "\n",
    "**Intermediate flaw levels**\n",
    "For intermediate flaw values we have a mix in both quantities, this is for a 1/5 flaw:\n",
    "* $H_l: .8\\cdot hs + .2\\cdot(1-hs)$\n",
    "* $T_l: .2\\cdot hs + .8\\cdot(1-hs)$\n",
    "\n",
    "**General expression**  \n",
    "Regarding all above we can come up with a common expression for all the cases  \n",
    "$H_l = (1-f)\\cdot hs + f(1-hs)$  \n",
    "$T_l = f\\cdot hs + (1-f)\\cdot(1-hs)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe22874-1308-46cc-8549-21e1f44cf0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here\n",
    "from empiricaldist import Pmf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# The hypothesis space represents all possible fairnesses of the coin\n",
    "# Where 0 means 100% tail biased and 1 100% head-biased\n",
    "hs = np.linspace(0, 1, 101)\n",
    "\n",
    "def calc_posterior(hs, dataset, flaw=0):\n",
    "    \"\"\"\n",
    "    Calculates the posterior probability.\n",
    "    \n",
    "    Args:\n",
    "        hs: numpy array with the hypothesis space\n",
    "        dataset: a string with the outcome of the experiment.\n",
    "        flaw: a float that indicates how flawed is the machine.\n",
    "    returns: Pmf with the posterior probability for the given args.\n",
    "    \"\"\"\n",
    "    prior = Pmf(1, hs)\n",
    "    assert flaw >= 0 and flaw <= 1\n",
    "    \n",
    "    likelihood = {\n",
    "        'H': (1-flaw) * hs + flaw * (1-hs),\n",
    "        'T': flaw * hs + (1-flaw) * (1-hs)\n",
    "    }\n",
    "\n",
    "    posterior = prior.copy()\n",
    "\n",
    "    for flip in dataset:\n",
    "        posterior *= likelihood[flip]\n",
    "\n",
    "    posterior.normalize()\n",
    "    return posterior\n",
    "\n",
    "dataset = 140 * 'H' + 110 * 'T'\n",
    "y0 = calc_posterior(hs, dataset)\n",
    "y2 = calc_posterior(hs, dataset, flaw=.2)\n",
    "y4 = calc_posterior(hs, dataset, flaw=.4)\n",
    "y5 = calc_posterior(hs, dataset, flaw=.5)\n",
    "\n",
    "sns.lineplot(x=hs, y=y0, label='y0');\n",
    "sns.lineplot(x=hs, y=y2, label='y=.2');\n",
    "sns.lineplot(x=hs, y=y4, label='y=.4');\n",
    "sns.lineplot(x=hs, y=y5, label='y=.5');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ca8c0-7466-4c4f-8b61-ecc646f9b099",
   "metadata": {},
   "source": [
    "# 24/07/2021 Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07734ce1-0d0e-4f25-8db3-a7f927ffbcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# The hypothesis space represents all possible fairnesses of coins where 0 means\n",
    "# a 100% tail biased coin and 1 represents a 100% head biased one\n",
    "hs = np.linspace(0, 1, 101)\n",
    "\n",
    "# Examine what happens at the extremes for possibility\n",
    "# y=0 means that the machine always reports the outcome of the coin so the\n",
    "# likelihoods are those of a regular coin:\n",
    "likes_y0 = {\n",
    "    'H': hs,\n",
    "    'T': 1-hs\n",
    "}\n",
    "\n",
    "# Conversely, y=1 means that the machine always fails the outcome of the flip,\n",
    "# so we have to swap the likelihoods\n",
    "likes_y1 = {\n",
    "    'H': 1-hs,\n",
    "    'T': hs\n",
    "}\n",
    "\n",
    "# Finding the likelihood as a function of y\n",
    "# let's split the problem by outcome, first heads.\n",
    "# We have to find a function of y such that when y=0 returns hs and when y=1\n",
    "# returns 1-hs. That function is y + hs - 2yhs\n",
    "# Now tails. This is quite straightforward as we only have to replace hs by\n",
    "# 1-hs\n",
    "def get_likes_y(y=0):\n",
    "    \"\"\"Return the likelihood as a function of y.\"\"\"\n",
    "    return {\n",
    "        'H': y + hs - 2*hs*y,\n",
    "        'T': y + 1 - hs -(2*y*(1-hs))\n",
    "    }\n",
    "\n",
    "# let's do some assertions that confirm above formula\n",
    "likes_y = get_likes_y()\n",
    "assert (likes_y['H'] == hs).all()\n",
    "assert (likes_y['T'] == (1-hs)).all()\n",
    "\n",
    "likes_y = get_likes_y(y=1)\n",
    "assert np.allclose(likes_y['H'], (1-hs)) # because floating point arithmetic\n",
    "assert np.allclose(likes_y['T'], hs)\n",
    "\n",
    "# Even more, y=.5 should give a steady value of .5 as our uncertainty is max\n",
    "likes_y = get_likes_y(y=.5)\n",
    "assert np.allclose(likes_y['H'], .5)\n",
    "assert np.allclose(likes_y['T'], .5)\n",
    "\n",
    "# Machine report\n",
    "report = 140 * 'H' + 110 * 'T'\n",
    "\n",
    "def find_map(posterior):\n",
    "    \"\"\"Return the index where the max probability lives.\"\"\"\n",
    "    return np.where(posterior==posterior.max())[0][0]\n",
    "\n",
    "def find_confidence_interval(posterior):\n",
    "    \"\"\"Return the lower and upper bounds indices for a 90% ci.\"\"\"\n",
    "    cdf = posterior.cumsum()\n",
    "    lower = np.where(cdf >= .05)[0][0]\n",
    "    upper = np.where(cdf <= .95)[0][-1]\n",
    "    return lower, upper\n",
    "\n",
    "for y in (.0, .2, .4, .5):\n",
    "    likes_y = get_likes_y(y)\n",
    "    posterior = np.ones(101)\n",
    "    for flip in report:\n",
    "        posterior *= likes_y[flip]\n",
    "    posterior /= posterior.sum()\n",
    "    sns.lineplot(x=hs, y=posterior, label=f\"y={y}\");\n",
    "    MAP = find_map(posterior)\n",
    "    lower, upper = find_confidence_interval(posterior)\n",
    "    print(f\"the MAP for y={y} is {hs[MAP]} and the confidence interval lays between {hs[lower]} and {hs[upper]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64c723-43f3-4ede-bc65-d7a45019f0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
